# ğŸ§  LLM-Powered Exam Invigilation System

This project is an AI-powered exam invigilation system that leverages OpenAI's language models to analyze student behavior and event logs during online exams, detecting potential anomalies and generating structured reports. It aims to enhance academic integrity in virtual assessment environments.

---

## ğŸš€ Features

- âœ… Real-time log monitoring and event tracking
- âœ… Behavior analysis using OpenAI's GPT models
- âœ… PDF and text report generation summarizing exam anomalies
- âœ… Streamlined and automated CLI-based workflow

---

## ğŸ› ï¸ Tech Stack

- **Python 3.11**
- **OpenAI GPT API**
- **reportlab** â€“ PDF generation
- **dotenv** â€“ environment variable management
- **JSON** â€“ event log handling
- **Command Line Interface (CLI)**

---


## ğŸ“Œ Prerequisites

- Python 3.10 or later
- OpenAI account with an API key

---

## ğŸ”§ Installation
   ## Clone the repo
     git clone https://github.com/your-username/llm-exam-invigilation.git
     cd llm-exam-invigilation

   ## Set your OpenAI API Key
    echo OPENAI_API_KEY=your-key-here > .env

   ## Install dependencies
    pip install -r requirements.txt

## ğŸ“„ License
This project is licensed under the MIT License.

## ğŸ™‹â€â™‚ï¸ Contributions
Pull requests and suggestions are welcome! Please open an issue first to discuss what you would like to change.

## ğŸ“« Contact
For any queries, contact shubamlunawat15@gmail.com.

